{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2nwPETTsAgKy",
        "zSaq-Xjn5GJ4",
        "SVtIZ2wo0kco"
      ],
      "authorship_tag": "ABX9TyOHYQLRXo3scmqb85Fcp//B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoloAvesani/Mining_Project/blob/main/that's_good_OK_APRIORI%2C_FP_GROWTH_and_ECLAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset generator\n",
        "https://github.com/jeffheaton/papers/blob/master/2016/ieee-freq-item/GenerateFreqData.py\n"
      ],
      "metadata": {
        "id": "2nwPETTsAgKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python script was used to collect the data for following paper/conference:\n",
        "#\n",
        "# Heaton, J. (2016, April). Comparing Dataset Characteristics that Favor the Apriori, \n",
        "# Eclat or FP-Growth Frequent Itemset Mining Algorithms. In SoutheastCon 2015 (pp. 1-6). IEEE.\n",
        "#\n",
        "# http://www.jeffheaton.com\n",
        "#\n",
        "\n",
        "# Generate benchmark data for frequent itemset mining.\n",
        "__author__ = 'jheaton'\n",
        "import random\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "def sizeof_fmt(num):\n",
        "    for x in ['','k','m','g']:\n",
        "        if num < 1000.0:\n",
        "            return \"%3.1f%s\" % (num, x)\n",
        "        num /= 1000.0\n",
        "    return \"%3.1f%s\" % (num, 't')\n",
        "\n",
        "def generate_itemset(row_count, max_per_basket, num_freq_sets, item_count, prob_frequent):\n",
        "    '''\n",
        "    Generate a dataset of frequent items. These paramaters can be changed to \n",
        "    determine the type of data to generate.\n",
        "\n",
        "    :param int row_count: The number of rows in the dataset.\n",
        "    :param int max_per_basket: Maximum number of items per basket.\n",
        "    :param int num_freq_sets: The number of unique frequent item sets.\n",
        "    :param int item_count: The number of unique items.\n",
        "    :param float prob_frequent: The probability of a basket containing a frequent itemset.\n",
        "    '''\n",
        "    # Generate the data\n",
        "    pop_frequent = [\"F\"+str(n) for n in range(0,max_per_basket)]\n",
        "    pop_regular = [\"I\"+str(n) for n in range(max_per_basket,item_count)]\n",
        "    freq_itemsets = []\n",
        "\n",
        "    # Create a filename that encodes the max_per_basket and basket_count into\n",
        "    # the filename.\n",
        "    filename = str(prob_frequent)+\"_tsz\" \\\n",
        "        + str(max_per_basket)+'_tct' \\\n",
        "         +sizeof_fmt(row_count)+'.txt'\n",
        "\n",
        "    for i in tqdm(range(num_freq_sets),desc=f\"{filename}:pass 1/2\"):\n",
        "        cnt = random.randint(1,max_per_basket)\n",
        "        freq_itemsets.append(random.sample(pop_frequent,cnt))\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        for i in tqdm(range(row_count),desc=f\"{filename}:pass 2/2\"):\n",
        "            line = []\n",
        "\n",
        "            cnt = random.randint(1,max_per_basket)\n",
        "            if random.random()<=prob_frequent:\n",
        "                idx = random.randint(0,len(freq_itemsets)-1)\n",
        "                for j in range(len(freq_itemsets[idx])):\n",
        "                    line.append(freq_itemsets[idx][j])\n",
        "\n",
        "            needed = max(0,cnt - len(line))\n",
        "            line = line + random.sample(pop_regular,needed)\n",
        "\n",
        "            f.write(\" \".join(line)+\"\\n\")\n",
        "\n",
        "random.seed(1000)"
      ],
      "metadata": {
        "id": "MBfjF7BNWjEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = generate_itemset(200000, 50, 100, 500, 0.5)\n",
        "\n",
        "    #Generate a dataset of frequent items. These paramaters can be changed to \n",
        "    #determine the type of data to generate.\n",
        "\n",
        "    #:param int row_count: The number of rows in the dataset. (in this case they are 10000)\n",
        "    #:param int max_per_basket: Maximum number of items per basket. (max 100 items per basket)\n",
        "    #:param int num_freq_sets: The number of unique frequent item sets. (100 freq item sets)\n",
        "    #:param int item_count: The number of unique items. (500 unique items)\n",
        "    #:param float prob_frequent: The probability of a basket containing a frequent itemset. (50% is the probability that a basket contains a freq itemset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvOQHH1IW1kU",
        "outputId": "19b7c55f-8922-4fe2-ea1c-b55c430dce21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0.5_tsz50_tct200.0k.txt:pass 1/2: 100%|██████████| 100/100 [00:00<00:00, 27385.11it/s]\n",
            "0.5_tsz50_tct200.0k.txt:pass 2/2: 100%|██████████| 200000/200000 [00:04<00:00, 47323.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv('0.5_tsz50_tct200.0k.txt')"
      ],
      "metadata": {
        "id": "JqYFzPT-W_7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I want the dataset to be a np.array\n",
        "dataset_array = np.array(dataset)"
      ],
      "metadata": {
        "id": "7aOoT9jmXDDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_array[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx2y0bjdXDFr",
        "outputId": "a7adc8a3-feef-43bc-8755-232c5ef0d5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['F8 F2 F26 F3 F25 F6 F43 F24 F42 F4 F13 F16 F36 F5 F47 F19 F35 F39 F48 F10 F22 F23 F34 F11 F18 F29 F7 F20 F30 F33 F27 F44 F21'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since the array contains baskets with only a string of element and not a list of elements, I need to fix this thing\n",
        "new_array = []\n",
        "for i in range(len(dataset_array)):\n",
        "    split_elements = np.char.split(dataset_array[i].astype(str))\n",
        "    ok_split_elements = (split_elements[0])\n",
        "    new_array.append(ok_split_elements)"
      ],
      "metadata": {
        "id": "X0HQOANnXDIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now it works\n",
        "new_array[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "e83QYxtzXLO9",
        "outputId": "a91baa61-247f-489d-d1e9-fd209e02f985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'F2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_array[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DUfDcj3YTyX",
        "outputId": "ecc5e7be-fcfe-44b0-e44e-620d009fd7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['F8',\n",
              " 'F2',\n",
              " 'F26',\n",
              " 'F3',\n",
              " 'F25',\n",
              " 'F6',\n",
              " 'F43',\n",
              " 'F24',\n",
              " 'F42',\n",
              " 'F4',\n",
              " 'F13',\n",
              " 'F16',\n",
              " 'F36',\n",
              " 'F5',\n",
              " 'F47',\n",
              " 'F19',\n",
              " 'F35',\n",
              " 'F39',\n",
              " 'F48',\n",
              " 'F10',\n",
              " 'F22',\n",
              " 'F23',\n",
              " 'F34',\n",
              " 'F11',\n",
              " 'F18',\n",
              " 'F29',\n",
              " 'F7',\n",
              " 'F20',\n",
              " 'F30',\n",
              " 'F33',\n",
              " 'F27',\n",
              " 'F44',\n",
              " 'F21']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_array[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_2QPxuyXLRf",
        "outputId": "bdf47597-6998-45e6-bb2f-1f186bcf10fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#apriori\n",
        "\n"
      ],
      "metadata": {
        "id": "4Gcs6DIs04MR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CpB3JTZo0-RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apyori"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg7vSIzxGOaK",
        "outputId": "def28669-69dd-44dd-9d6e-d890db48ec36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: apyori in /usr/local/lib/python3.10/dist-packages (1.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apriori algorithm using the library--> it shows me all the possible k-frequent itemsets with the support\n",
        "\n",
        "from apyori import apriori\n",
        "import time\n",
        "\n",
        "# Example dataset\n",
        "dataset = new_array\n",
        "\n",
        "# Minimum support threshold\n",
        "min_support = 0.25\n",
        "\n",
        "start = time.time()\n",
        "# Apply the Apriori algorithm\n",
        "results = list(apriori(dataset, min_support=min_support))\n",
        "\n",
        "# Print all frequent itemsets\n",
        "for itemset in results:\n",
        "    print(itemset)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print('Time required:', end - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmHlil-_FuFf",
        "outputId": "84ebbe52-e259-4987-af84-dc321aa2dc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RelationRecord(items=frozenset({'F11'}), support=0.2664113320566603, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F11'}), confidence=0.2664113320566603, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F12'}), support=0.29085145425727127, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F12'}), confidence=0.29085145425727127, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F13'}), support=0.28638143190715953, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F13'}), confidence=0.28638143190715953, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F14'}), support=0.28571142855714277, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F14'}), confidence=0.28571142855714277, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F15'}), support=0.2703363516817584, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F15'}), confidence=0.2703363516817584, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F16'}), support=0.2653413267066335, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F16'}), confidence=0.2653413267066335, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F17'}), support=0.2806864034320172, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F17'}), confidence=0.2806864034320172, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F2'}), support=0.2963464817324087, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F2'}), confidence=0.2963464817324087, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F20'}), support=0.26556132780663905, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F20'}), confidence=0.26556132780663905, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F21'}), support=0.25038625193125963, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F21'}), confidence=0.25038625193125963, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F22'}), support=0.29124145620728104, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F22'}), confidence=0.29124145620728104, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F23'}), support=0.25608628043140214, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F23'}), confidence=0.25608628043140214, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F24'}), support=0.2556162780813904, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F24'}), confidence=0.2556162780813904, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F25'}), support=0.26524632623163114, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F25'}), confidence=0.26524632623163114, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F27'}), support=0.29528147640738206, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F27'}), confidence=0.29528147640738206, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F28'}), support=0.2714863574317872, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F28'}), confidence=0.2714863574317872, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F3'}), support=0.28132140660703303, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F3'}), confidence=0.28132140660703303, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F30'}), support=0.26656133280666405, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F30'}), confidence=0.26656133280666405, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F31'}), support=0.3071515357576788, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F31'}), confidence=0.3071515357576788, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F32'}), support=0.28114140570702856, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F32'}), confidence=0.28114140570702856, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F33'}), support=0.27077135385676926, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F33'}), confidence=0.27077135385676926, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F34'}), support=0.2510312551562758, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F34'}), confidence=0.2510312551562758, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F35'}), support=0.2515512577562888, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F35'}), confidence=0.2515512577562888, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F38'}), support=0.2555812779063895, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F38'}), confidence=0.2555812779063895, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F39'}), support=0.2862964314821574, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F39'}), confidence=0.2862964314821574, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F4'}), support=0.29654148270741354, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F4'}), confidence=0.29654148270741354, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F40'}), support=0.28540642703213515, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F40'}), confidence=0.28540642703213515, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F41'}), support=0.2763763818819094, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F41'}), confidence=0.2763763818819094, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F42'}), support=0.31624658123290617, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F42'}), confidence=0.31624658123290617, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F44'}), support=0.260601303006515, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F44'}), confidence=0.260601303006515, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F45'}), support=0.27573637868189343, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F45'}), confidence=0.27573637868189343, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F47'}), support=0.2716363581817909, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F47'}), confidence=0.2716363581817909, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F48'}), support=0.29642148210741054, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F48'}), confidence=0.29642148210741054, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F5'}), support=0.2765563827819139, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F5'}), confidence=0.2765563827819139, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F6'}), support=0.3109515547577738, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F6'}), confidence=0.3109515547577738, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F7'}), support=0.25054125270626354, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F7'}), confidence=0.25054125270626354, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F8'}), support=0.3160315801579008, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F8'}), confidence=0.3160315801579008, lift=1.0)])\n",
            "RelationRecord(items=frozenset({'F9'}), support=0.25106625533127663, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'F9'}), confidence=0.25106625533127663, lift=1.0)])\n",
            "Time required: 5.469318628311157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fp-growth\n",
        "https://github.com/JackHCC/Apriori-and-FP_Growth/blob/master/FP_growth.py\n"
      ],
      "metadata": {
        "id": "zSaq-Xjn5GJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fp-growth\n",
        "\n",
        "# fp-growth\n",
        "\n",
        "from collections import defaultdict, namedtuple\n",
        "import time\n",
        "\n",
        "def find_frequent_itemsets(transactions, minimum_support, include_support=False):\n",
        "    # Function to find frequent itemsets in the transactions dataset\n",
        "\n",
        "    items = defaultdict(lambda: 0)\n",
        "\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            items[item] += 1\n",
        "\n",
        "    # Filtering frequent 1-itemsets\n",
        "    items = dict((item, support) for item, support in items.items()\n",
        "        if support >= minimum_support)\n",
        "\n",
        "    def clean_transaction(transaction):\n",
        "        transaction = filter(lambda v: v in items, transaction)\n",
        "        transaction_list = list(transaction)\n",
        "        transaction_list.sort(key=lambda v: items[v], reverse=True)\n",
        "        return transaction_list\n",
        "\n",
        "    # Constructing the FP-tree\n",
        "    master = FPTree()\n",
        "    for transaction in map(clean_transaction, transactions):\n",
        "        master.add(transaction)\n",
        "\n",
        "    def find_with_suffix(tree, suffix):\n",
        "        for item, nodes in tree.items():\n",
        "            support = sum(n.count for n in nodes)\n",
        "            if support >= minimum_support and item not in suffix:\n",
        "                found_set = [item] + suffix\n",
        "                yield (found_set, support) if include_support else found_set\n",
        "\n",
        "                cond_tree = conditional_tree_from_paths(tree.prefix_paths(item))\n",
        "                for s in find_with_suffix(cond_tree, found_set):\n",
        "                    yield s\n",
        "\n",
        "    for itemset in find_with_suffix(master, []):\n",
        "        yield itemset\n",
        "\n",
        "class FPTree(object):\n",
        "    # FP-tree data structure\n",
        "\n",
        "    Route = namedtuple('Route', 'head tail')\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize the root node and routes\n",
        "        self._root = FPNode(self, None, None)\n",
        "        self._routes = {}\n",
        "\n",
        "    @property\n",
        "    def root(self):\n",
        "        # Create the root node\n",
        "        return self._root\n",
        "\n",
        "    def add(self, transaction):\n",
        "        # Add a transaction to the tree\n",
        "        point = self._root\n",
        "\n",
        "        for item in transaction:\n",
        "            next_point = point.search(item)\n",
        "            if next_point:\n",
        "                # Current node already exists\n",
        "                next_point.increment()\n",
        "            else:\n",
        "                # Create a new node\n",
        "                next_point = FPNode(self, item)\n",
        "                point.add(next_point)\n",
        "\n",
        "                # Update the routes\n",
        "                self._update_route(next_point)\n",
        "\n",
        "            point = next_point\n",
        "\n",
        "    def _update_route(self, point):\n",
        "        assert self is point.tree\n",
        "\n",
        "        try:\n",
        "            route = self._routes[point.item]\n",
        "            route[1].neighbor = point  # route[1] is the tail\n",
        "            self._routes[point.item] = self.Route(route[0], point)\n",
        "        except KeyError:\n",
        "            # Start a new node\n",
        "            self._routes[point.item] = self.Route(point, point)\n",
        "\n",
        "    def items(self):\n",
        "        # Iterate over the items in the tree\n",
        "        for item in self._routes.keys():\n",
        "            yield (item, self.nodes(item))\n",
        "\n",
        "    def nodes(self, item):\n",
        "        # Iterate over the nodes associated with an item\n",
        "        try:\n",
        "            node = self._routes[item][0]\n",
        "        except KeyError:\n",
        "            return\n",
        "\n",
        "        while node:\n",
        "            yield node\n",
        "            node = node.neighbor\n",
        "\n",
        "    def prefix_paths(self, item):\n",
        "        # Generate prefix paths for an item\n",
        "        def collect_path(node):\n",
        "            path = []\n",
        "            while node and not node.root:\n",
        "                path.append(node)\n",
        "                node = node.parent\n",
        "            path.reverse()\n",
        "            return path\n",
        "\n",
        "        return (collect_path(node) for node in self.nodes(item))\n",
        "\n",
        "    def inspect(self):\n",
        "        # Print the tree structure\n",
        "        self.root.inspect(1)\n",
        "\n",
        "        for item, nodes in self.items():\n",
        "            for node in nodes:\n",
        "                print('    %r' % node)\n",
        "\n",
        "def conditional_tree_from_paths(paths):\n",
        "    # Construct a conditional tree from paths\n",
        "    tree = FPTree()\n",
        "    condition_item = None\n",
        "    items = set()\n",
        "\n",
        "    for path in paths:\n",
        "        if condition_item is None:\n",
        "            condition_item = path[-1].item\n",
        "\n",
        "        point = tree.root\n",
        "        for node in path:\n",
        "            next_point = point.search(node.item)\n",
        "            if not next_point:\n",
        "                # Add a new node to the tree\n",
        "                items.add(node.item)\n",
        "                count = node.count if node.item == condition_item else 0\n",
        "                next_point = FPNode(tree, node.item, count)\n",
        "                point.add(next_point)\n",
        "                tree._update_route(next_point)\n",
        "            point = next_point\n",
        "\n",
        "    assert condition_item is not None\n",
        "\n",
        "    # Calculate the counts for nodes\n",
        "    for path in tree.prefix_paths(condition_item):\n",
        "        count = path[-1].count\n",
        "        for node in reversed(path[:-1]):\n",
        "            node._count += count\n",
        "\n",
        "    return tree\n",
        "\n",
        "class FPNode(object):\n",
        "    # FP-tree node\n",
        "\n",
        "    def __init__(self, tree, item, count=1):\n",
        "        self._tree = tree\n",
        "        self._item = item\n",
        "        self._count = count\n",
        "        self._parent = None\n",
        "        self._children = {}\n",
        "        self._neighbor = None\n",
        "\n",
        "    def add(self, child):\n",
        "        # Add a child node\n",
        "\n",
        "        if not isinstance(child, FPNode):\n",
        "            raise TypeError(\"Can only add other FPNodes as children\")\n",
        "\n",
        "        if not child.item in self._children:\n",
        "            self._children[child.item] = child\n",
        "            child.parent = self\n",
        "\n",
        "    def search(self, item):\n",
        "        # Search for a child node with the given item\n",
        "        try:\n",
        "            return self._children[item]\n",
        "        except KeyError:\n",
        "            return None\n",
        "\n",
        "    def __contains__(self, item):\n",
        "        return item in self._children\n",
        "\n",
        "    @property\n",
        "    def tree(self):\n",
        "        return self._tree\n",
        "\n",
        "    @property\n",
        "    def item(self):\n",
        "        return self._item\n",
        "\n",
        "    @property\n",
        "    def count(self):\n",
        "        return self._count\n",
        "\n",
        "    def increment(self):\n",
        "        if self._count is None:\n",
        "            raise ValueError(\"Root nodes have no associated count.\")\n",
        "        self._count += 1\n",
        "\n",
        "    @property\n",
        "    def root(self):\n",
        "        return self._item is None and self._count is None\n",
        "\n",
        "    @property\n",
        "    def leaf(self):\n",
        "        return len(self._children) == 0\n",
        "\n",
        "    @property\n",
        "    def parent(self):\n",
        "        return self._parent\n",
        "\n",
        "    @parent.setter\n",
        "    def parent(self, value):\n",
        "        if value is not None and not isinstance(value, FPNode):\n",
        "            raise TypeError(\"A node must have an FPNode as a parent.\")\n",
        "        if value and value.tree is not self.tree:\n",
        "            raise ValueError(\"Cannot have a parent from another tree.\")\n",
        "        self._parent = value\n",
        "\n",
        "    @property\n",
        "    def neighbor(self):\n",
        "        return self._neighbor\n",
        "\n",
        "    @neighbor.setter\n",
        "    def neighbor(self, value):\n",
        "        if value is not None and not isinstance(value, FPNode):\n",
        "            raise TypeError(\"A node must have an FPNode as a neighbor.\")\n",
        "        if value and value.tree is not self.tree:\n",
        "            raise ValueError(\"Cannot have a neighbor from another tree.\")\n",
        "        self._neighbor = value\n",
        "\n",
        "    @property\n",
        "    def children(self):\n",
        "        return tuple(self._children.values())\n",
        "\n",
        "    def inspect(self, depth=0):\n",
        "        for child in self.children:\n",
        "            child.inspect(depth + 1)\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.root:\n",
        "            return \"<%s (root)>\" % type(self).__name__\n",
        "        return \"<%s %r (%r)>\" % (type(self).__name__, self.item, self.count)\n"
      ],
      "metadata": {
        "id": "ys5DGrOkYg1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "dataset = new_array\n",
        "# Main function\n",
        "if __name__ == '__main__':\n",
        "    # Call find_frequent_itemsets() to generate frequent itemsets\n",
        "    start = time.time()\n",
        "\n",
        "    total_baskets = len(dataset)\n",
        "    min_support = 0.25 * total_baskets\n",
        "\n",
        "    frequent_itemsets = find_frequent_itemsets(dataset, minimum_support=min_support, include_support=True)\n",
        "\n",
        "    result = []\n",
        "    for itemset, support in frequent_itemsets:\n",
        "        result.append((itemset, support))\n",
        "\n",
        "    result = sorted(result, key=lambda i: i[0])\n",
        "    for itemset, support in result:\n",
        "        print(str(itemset) + ' ' + str(support/total_baskets))\n",
        "\n",
        "    end = time.time()\n",
        "    print('Execution time:', str(end - start))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2i7WrComqd1",
        "outputId": "e5ac8b82-330b-4d45-a325-4809ea78e6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F11'] 0.2664113320566603\n",
            "['F12'] 0.29085145425727127\n",
            "['F13'] 0.28638143190715953\n",
            "['F14'] 0.28571142855714277\n",
            "['F15'] 0.2703363516817584\n",
            "['F16'] 0.2653413267066335\n",
            "['F17'] 0.2806864034320172\n",
            "['F2'] 0.2963464817324087\n",
            "['F20'] 0.26556132780663905\n",
            "['F21'] 0.25038625193125963\n",
            "['F22'] 0.29124145620728104\n",
            "['F23'] 0.25608628043140214\n",
            "['F24'] 0.2556162780813904\n",
            "['F25'] 0.26524632623163114\n",
            "['F27'] 0.29528147640738206\n",
            "['F28'] 0.2714863574317872\n",
            "['F3'] 0.28132140660703303\n",
            "['F30'] 0.26656133280666405\n",
            "['F31'] 0.3071515357576788\n",
            "['F32'] 0.28114140570702856\n",
            "['F33'] 0.27077135385676926\n",
            "['F34'] 0.2510312551562758\n",
            "['F35'] 0.2515512577562888\n",
            "['F38'] 0.2555812779063895\n",
            "['F39'] 0.2862964314821574\n",
            "['F4'] 0.29654148270741354\n",
            "['F40'] 0.28540642703213515\n",
            "['F41'] 0.2763763818819094\n",
            "['F42'] 0.31624658123290617\n",
            "['F44'] 0.260601303006515\n",
            "['F45'] 0.27573637868189343\n",
            "['F47'] 0.2716363581817909\n",
            "['F48'] 0.29642148210741054\n",
            "['F5'] 0.2765563827819139\n",
            "['F6'] 0.3109515547577738\n",
            "['F7'] 0.25054125270626354\n",
            "['F8'] 0.3160315801579008\n",
            "['F9'] 0.25106625533127663\n",
            "Execution time: 3.0959486961364746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# eclat\n",
        "https://github.com/jagdeep227/Frequent_itemset_mining/blob/main/Eclat_g.py\n"
      ],
      "metadata": {
        "id": "SVtIZ2wo0kco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eclat\n",
        "#eclat\n",
        "import time\n",
        "\n",
        "FreqItems = dict()\n",
        "support = dict()\n",
        "\n",
        "\n",
        "def eclat(prefix, items, dict_id ,minsup,cnt):\n",
        "    \n",
        "    while items:\n",
        "        i ,itids = items.pop()\n",
        "        isupp = len(itids)\n",
        "        if isupp >= minsup*cnt:\n",
        "            print(prefix + [i], isupp/len(dataset))\n",
        "            FreqItems[frozenset(prefix + [i])] = isupp\n",
        "            suffix = []\n",
        "            for j, ojtids in items:\n",
        "                jtids = itids & ojtids\n",
        "                if len(jtids ) >= minsup*cnt:\n",
        "                    suffix.append((j, jtids))\n",
        "            dict_id += 1\n",
        "            eclat(prefix +[i], sorted(suffix, key=lambda item: len(item[1]), reverse=True), dict_id ,minsup,cnt)"
      ],
      "metadata": {
        "id": "dRaVlQOSkHLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "items = {}\n",
        "\n",
        "for transaction_id, transaction in enumerate(dataset):\n",
        "    for item in transaction:\n",
        "        if item in items:\n",
        "            items[item].add(transaction_id)\n",
        "        else:\n",
        "            items[item] = {transaction_id}\n",
        "\n",
        "    # Convert the dictionary items into a list of tuples\n",
        "items = [(item, itids) for item, itids in items.items()]"
      ],
      "metadata": {
        "id": "vAiJEwuKlV0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "dataset = new_array\n",
        "# Main function\n",
        "if __name__ == '__main__':\n",
        "    # Call find_frequent_itemsets() to generate frequent itemsets\n",
        "    start = time.time()\n",
        "\n",
        "    cnt = len(dataset)\n",
        "    minsup = 0.25\n",
        "    # Function call to start ECLAT algorithm\n",
        "    eclat([], sorted(items, key=lambda item: len(item[1]), reverse=True), 1, minsup, cnt)\n",
        "\n",
        "    result = []\n",
        "    for itemset, support in frequent_itemsets:\n",
        "        result.append((itemset, support))\n",
        "\n",
        "    result = sorted(result, key=lambda i: i[0])\n",
        "    for itemset, support in result:\n",
        "        print(str(itemset) + ' ' + str(support/total_baskets))\n",
        "\n",
        "    end = time.time()\n",
        "    print('Execution time:', str(end - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIUzP6VykmrA",
        "outputId": "8666375f-fcbe-4e7b-904e-3b1d23fc7bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F21'] 0.25038625193125963\n",
            "['F7'] 0.25054125270626354\n",
            "['F34'] 0.2510312551562758\n",
            "['F9'] 0.25106625533127663\n",
            "['F35'] 0.2515512577562888\n",
            "['F38'] 0.2555812779063895\n",
            "['F24'] 0.2556162780813904\n",
            "['F23'] 0.25608628043140214\n",
            "['F44'] 0.260601303006515\n",
            "['F25'] 0.26524632623163114\n",
            "['F16'] 0.2653413267066335\n",
            "['F20'] 0.26556132780663905\n",
            "['F11'] 0.2664113320566603\n",
            "['F30'] 0.26656133280666405\n",
            "['F15'] 0.2703363516817584\n",
            "['F33'] 0.27077135385676926\n",
            "['F28'] 0.2714863574317872\n",
            "['F47'] 0.2716363581817909\n",
            "['F45'] 0.27573637868189343\n",
            "['F41'] 0.2763763818819094\n",
            "['F5'] 0.2765563827819139\n",
            "['F17'] 0.2806864034320172\n",
            "['F32'] 0.28114140570702856\n",
            "['F3'] 0.28132140660703303\n",
            "['F40'] 0.28540642703213515\n",
            "['F14'] 0.28571142855714277\n",
            "['F39'] 0.2862964314821574\n",
            "['F13'] 0.28638143190715953\n",
            "['F12'] 0.29085145425727127\n",
            "['F22'] 0.29124145620728104\n",
            "['F27'] 0.29528147640738206\n",
            "['F2'] 0.2963464817324087\n",
            "['F48'] 0.29642148210741054\n",
            "['F4'] 0.29654148270741354\n",
            "['F31'] 0.3071515357576788\n",
            "['F6'] 0.3109515547577738\n",
            "['F8'] 0.3160315801579008\n",
            "['F42'] 0.31624658123290617\n",
            "Execution time: 3.597142219543457\n"
          ]
        }
      ]
    }
  ]
}