{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2nwPETTsAgKy",
        "zSaq-Xjn5GJ4",
        "SVtIZ2wo0kco"
      ],
      "authorship_tag": "ABX9TyP+l6aQFdYIhzBD/1LZhD7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoloAvesani/Mining_Project/blob/main/that's_good_OK_APRIORI%2C_FP_GROWTH_and_ECLAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset generator\n",
        "https://github.com/jeffheaton/papers/blob/master/2016/ieee-freq-item/GenerateFreqData.py\n"
      ],
      "metadata": {
        "id": "2nwPETTsAgKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python script was used to collect the data for following paper/conference:\n",
        "#\n",
        "# Heaton, J. (2016, April). Comparing Dataset Characteristics that Favor the Apriori, \n",
        "# Eclat or FP-Growth Frequent Itemset Mining Algorithms. In SoutheastCon 2015 (pp. 1-6). IEEE.\n",
        "#\n",
        "# http://www.jeffheaton.com\n",
        "#\n",
        "\n",
        "# Generate benchmark data for frequent itemset mining.\n",
        "__author__ = 'jheaton'\n",
        "import random\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "def sizeof_fmt(num):\n",
        "    for x in ['','k','m','g']:\n",
        "        if num < 1000.0:\n",
        "            return \"%3.1f%s\" % (num, x)\n",
        "        num /= 1000.0\n",
        "    return \"%3.1f%s\" % (num, 't')\n",
        "\n",
        "def generate_itemset(row_count, max_per_basket, num_freq_sets, item_count, prob_frequent):\n",
        "    '''\n",
        "    Generate a dataset of frequent items. These paramaters can be changed to \n",
        "    determine the type of data to generate.\n",
        "\n",
        "    :param int row_count: The number of rows in the dataset.\n",
        "    :param int max_per_basket: Maximum number of items per basket.\n",
        "    :param int num_freq_sets: The number of unique frequent item sets.\n",
        "    :param int item_count: The number of unique items.\n",
        "    :param float prob_frequent: The probability of a basket containing a frequent itemset.\n",
        "    '''\n",
        "    # Generate the data\n",
        "    pop_frequent = [\"F\"+str(n) for n in range(0,max_per_basket)]\n",
        "    pop_regular = [\"I\"+str(n) for n in range(max_per_basket,item_count)]\n",
        "    freq_itemsets = []\n",
        "\n",
        "    # Create a filename that encodes the max_per_basket and basket_count into\n",
        "    # the filename.\n",
        "    filename = str(prob_frequent)+\"_tsz\" \\\n",
        "        + str(max_per_basket)+'_tct' \\\n",
        "         +sizeof_fmt(row_count)+'.txt'\n",
        "\n",
        "    for i in tqdm(range(num_freq_sets),desc=f\"{filename}:pass 1/2\"):\n",
        "        cnt = random.randint(1,max_per_basket)\n",
        "        freq_itemsets.append(random.sample(pop_frequent,cnt))\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        for i in tqdm(range(row_count),desc=f\"{filename}:pass 2/2\"):\n",
        "            line = []\n",
        "\n",
        "            cnt = random.randint(1,max_per_basket)\n",
        "            if random.random()<=prob_frequent:\n",
        "                idx = random.randint(0,len(freq_itemsets)-1)\n",
        "                for j in range(len(freq_itemsets[idx])):\n",
        "                    line.append(freq_itemsets[idx][j])\n",
        "\n",
        "            needed = max(0,cnt - len(line))\n",
        "            line = line + random.sample(pop_regular,needed)\n",
        "\n",
        "            f.write(\" \".join(line)+\"\\n\")\n",
        "\n",
        "random.seed(1000)\n",
        "ROWS = 1000000\n",
        "\n",
        "for i in range(10,110,100):\n",
        "    generate_itemset(ROWS, i, 100, 50000, 0.5)\n",
        "\n",
        "##for i in range(1,9):\n",
        "  #  generate_itemset(ROWS, 50, 100, 50000, i/10.0)"
      ],
      "metadata": {
        "id": "MBfjF7BNWjEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76b1f7b-9f7a-4292-97a7-4ab88ff8a2aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0.5_tsz10_tct1.0m.txt:pass 1/2: 100%|██████████| 100/100 [00:00<00:00, 61771.78it/s]\n",
            "0.5_tsz10_tct1.0m.txt:pass 2/2: 100%|██████████| 1000000/1000000 [00:06<00:00, 153195.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    #Generate a dataset of frequent items. These paramaters can be changed to \n",
        "    #determine the type of data to generate.\n",
        "\n",
        "    #:param int row_count: The number of rows in the dataset. (in this case they are 10000)\n",
        "    #:param int max_per_basket: Maximum number of items per basket. (max 100 items per basket)\n",
        "    #:param int num_freq_sets: The number of unique frequent item sets. (100 freq item sets)\n",
        "    #:param int item_count: The number of unique items. (500 unique items)\n",
        "    #:param float prob_frequent: The probability of a basket containing a frequent itemset. (50% is the probability that a basket contains a freq itemset)"
      ],
      "metadata": {
        "id": "PvOQHH1IW1kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv('0.5_tsz10_tct1.0m.txt')"
      ],
      "metadata": {
        "id": "JqYFzPT-W_7q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I want the dataset to be a np.array\n",
        "dataset_array = np.array(dataset)\n",
        "\n",
        "print(dataset_array[0])\n",
        "\n",
        "# since the array contains baskets with only a string of element and not a list of elements, I need to fix this thing\n",
        "new_array = []\n",
        "for i in range(len(dataset_array)):\n",
        "    split_elements = np.char.split(dataset_array[i].astype(str))\n",
        "    ok_split_elements = (split_elements[0])\n",
        "    new_array.append(ok_split_elements)"
      ],
      "metadata": {
        "id": "7aOoT9jmXDDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958b88aa-2f41-400f-cfcf-e1ce13aaca86"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F1 F6 F4 F0 F8 F3 F7 F2 F5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now it works\n",
        "#new_array[1]"
      ],
      "metadata": {
        "id": "e83QYxtzXLO9"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new_array[0]"
      ],
      "metadata": {
        "id": "2DUfDcj3YTyX"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(new_array[0])"
      ],
      "metadata": {
        "id": "g_2QPxuyXLRf"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#apriori\n",
        "\n"
      ],
      "metadata": {
        "id": "4Gcs6DIs04MR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "APRIORI LIBRARY DOCUMENTATION"
      ],
      "metadata": {
        "id": "CpB3JTZo0-RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install apyori"
      ],
      "metadata": {
        "id": "Wg7vSIzxGOaK"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from apyori import apriori\n",
        "import time\n",
        "\n",
        "# Example dataset\n",
        "dataset = new_array\n",
        "\n",
        "# Minimum support threshold\n",
        "min_support = 0.2\n",
        "\n",
        "start = time.time()\n",
        "# Apply the Apriori algorithm\n",
        "results = list(apriori(dataset, min_support=min_support))\n",
        "\n",
        "# Print frequent itemsets and their support\n",
        "for itemset in results:\n",
        "    items = list(itemset.items)\n",
        "    support = itemset.support\n",
        "    print(items, support)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print('Time required:', end - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjr59AXI8iKG",
        "outputId": "628997a8-19f3-4054-a3da-3aea665a4543"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F0'] 0.2553262553262553\n",
            "['F1'] 0.23023523023523024\n",
            "['F10'] 0.2352062352062352\n",
            "['F11'] 0.26047026047026045\n",
            "['F12'] 0.23495723495723495\n",
            "['F13'] 0.23972623972623971\n",
            "['F14'] 0.25445125445125444\n",
            "['F15'] 0.27965427965427964\n",
            "['F16'] 0.23524223524223525\n",
            "['F17'] 0.25986325986325987\n",
            "['F18'] 0.23446323446323447\n",
            "['F19'] 0.24454224454224455\n",
            "['F2'] 0.26041926041926045\n",
            "['F20'] 0.22014322014322013\n",
            "['F21'] 0.27505427505427504\n",
            "['F22'] 0.22529122529122528\n",
            "['F23'] 0.22950722950722952\n",
            "['F24'] 0.2548062548062548\n",
            "['F25'] 0.26525026525026524\n",
            "['F26'] 0.29553329553329555\n",
            "['F27'] 0.2552142552142552\n",
            "['F28'] 0.24969724969724968\n",
            "['F29'] 0.2647642647642648\n",
            "['F3'] 0.2545812545812546\n",
            "['F30'] 0.2849142849142849\n",
            "['F31'] 0.2648362648362648\n",
            "['F32'] 0.2545392545392545\n",
            "['F33'] 0.2795122795122795\n",
            "['F34'] 0.25983325983325983\n",
            "['F35'] 0.2652022652022652\n",
            "['F37'] 0.23551323551323552\n",
            "['F38'] 0.29545429545429547\n",
            "['F39'] 0.26017626017626017\n",
            "['F4'] 0.245005245005245\n",
            "['F40'] 0.26995326995326996\n",
            "['F41'] 0.2859192859192859\n",
            "['F42'] 0.25004425004425007\n",
            "['F43'] 0.21934621934621934\n",
            "['F44'] 0.24001524001524002\n",
            "['F45'] 0.25005025005025006\n",
            "['F46'] 0.27494027494027495\n",
            "['F48'] 0.2401832401832402\n",
            "['F49'] 0.25955325955325953\n",
            "['F5'] 0.2704002704002704\n",
            "['F50'] 0.26985226985226984\n",
            "['F51'] 0.205001205001205\n",
            "['F52'] 0.25513325513325513\n",
            "['F53'] 0.24493724493724495\n",
            "['F54'] 0.26517326517326517\n",
            "['F55'] 0.26008526008526006\n",
            "['F56'] 0.2203832203832204\n",
            "['F57'] 0.2449112449112449\n",
            "['F58'] 0.27033627033627033\n",
            "['F59'] 0.25475525475525473\n",
            "['F6'] 0.2705102705102705\n",
            "['F7'] 0.25975125975125973\n",
            "['F8'] 0.23998623998624\n",
            "['F9'] 0.2501992501992502\n",
            "['F26', 'F11'] 0.21551121551121552\n",
            "['F58', 'F11'] 0.20068420068420068\n",
            "['F14', 'F15'] 0.20443820443820443\n",
            "['F26', 'F15'] 0.20484720484720484\n",
            "['F15', 'F30'] 0.20467220467220468\n",
            "['F15', 'F55'] 0.204991204991205\n",
            "['F26', 'F17'] 0.21496421496421497\n",
            "['F17', 'F41'] 0.2052162052162052\n",
            "['F46', 'F17'] 0.2047062047062047\n",
            "['F2', 'F30'] 0.20001820001820003\n",
            "['F21', 'F30'] 0.2003022003022003\n",
            "['F21', 'F5'] 0.2050942050942051\n",
            "['F26', 'F24'] 0.2152092152092152\n",
            "['F26', 'F30'] 0.20506320506320505\n",
            "['F33', 'F26'] 0.20971620971620972\n",
            "['F26', 'F35'] 0.20007320007320006\n",
            "['F26', 'F38'] 0.21538521538521538\n",
            "['F26', 'F41'] 0.205991205991206\n",
            "['F44', 'F26'] 0.20012620012620014\n",
            "['F54', 'F26'] 0.21035621035621035\n",
            "['F58', 'F26'] 0.21035121035121035\n",
            "['F26', 'F6'] 0.20562720562720563\n",
            "['F8', 'F26'] 0.20504120504120504\n",
            "['F32', 'F30'] 0.2047852047852048\n",
            "['F38', 'F46'] 0.20002520002520002\n",
            "['F58', 'F38'] 0.20553220553220553\n",
            "Time required: 44.9047327041626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fp-growth\n",
        "https://github.com/JackHCC/Apriori-and-FP_Growth/blob/master/FP_growth.py\n"
      ],
      "metadata": {
        "id": "zSaq-Xjn5GJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fp-growth\n",
        "\n",
        "# fp-growth\n",
        "\n",
        "from collections import defaultdict, namedtuple\n",
        "import time\n",
        "\n",
        "def find_frequent_itemsets(transactions, minimum_support, include_support=False):\n",
        "    # Function to find frequent itemsets in the transactions dataset\n",
        "\n",
        "    items = defaultdict(lambda: 0)\n",
        "\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            items[item] += 1\n",
        "\n",
        "    # Filtering frequent 1-itemsets\n",
        "    items = dict((item, support) for item, support in items.items()\n",
        "        if support >= minimum_support)\n",
        "\n",
        "    def clean_transaction(transaction):\n",
        "        transaction = filter(lambda v: v in items, transaction)\n",
        "        transaction_list = list(transaction)\n",
        "        transaction_list.sort(key=lambda v: items[v], reverse=True)\n",
        "        return transaction_list\n",
        "\n",
        "    # Constructing the FP-tree\n",
        "    master = FPTree()\n",
        "    for transaction in map(clean_transaction, transactions):\n",
        "        master.add(transaction)\n",
        "\n",
        "    def find_with_suffix(tree, suffix):\n",
        "        for item, nodes in tree.items():\n",
        "            support = sum(n.count for n in nodes)\n",
        "            if support >= minimum_support and item not in suffix:\n",
        "                found_set = [item] + suffix\n",
        "                yield (found_set, support) if include_support else found_set\n",
        "\n",
        "                cond_tree = conditional_tree_from_paths(tree.prefix_paths(item))\n",
        "                for s in find_with_suffix(cond_tree, found_set):\n",
        "                    yield s\n",
        "\n",
        "    for itemset in find_with_suffix(master, []):\n",
        "        yield itemset\n",
        "\n",
        "class FPTree(object):\n",
        "    # FP-tree data structure\n",
        "\n",
        "    Route = namedtuple('Route', 'head tail')\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize the root node and routes\n",
        "        self._root = FPNode(self, None, None)\n",
        "        self._routes = {}\n",
        "\n",
        "    @property\n",
        "    def root(self):\n",
        "        # Create the root node\n",
        "        return self._root\n",
        "\n",
        "    def add(self, transaction):\n",
        "        # Add a transaction to the tree\n",
        "        point = self._root\n",
        "\n",
        "        for item in transaction:\n",
        "            next_point = point.search(item)\n",
        "            if next_point:\n",
        "                # Current node already exists\n",
        "                next_point.increment()\n",
        "            else:\n",
        "                # Create a new node\n",
        "                next_point = FPNode(self, item)\n",
        "                point.add(next_point)\n",
        "\n",
        "                # Update the routes\n",
        "                self._update_route(next_point)\n",
        "\n",
        "            point = next_point\n",
        "\n",
        "    def _update_route(self, point):\n",
        "        assert self is point.tree\n",
        "\n",
        "        try:\n",
        "            route = self._routes[point.item]\n",
        "            route[1].neighbor = point  # route[1] is the tail\n",
        "            self._routes[point.item] = self.Route(route[0], point)\n",
        "        except KeyError:\n",
        "            # Start a new node\n",
        "            self._routes[point.item] = self.Route(point, point)\n",
        "\n",
        "    def items(self):\n",
        "        # Iterate over the items in the tree\n",
        "        for item in self._routes.keys():\n",
        "            yield (item, self.nodes(item))\n",
        "\n",
        "    def nodes(self, item):\n",
        "        # Iterate over the nodes associated with an item\n",
        "        try:\n",
        "            node = self._routes[item][0]\n",
        "        except KeyError:\n",
        "            return\n",
        "\n",
        "        while node:\n",
        "            yield node\n",
        "            node = node.neighbor\n",
        "\n",
        "    def prefix_paths(self, item):\n",
        "        # Generate prefix paths for an item\n",
        "        def collect_path(node):\n",
        "            path = []\n",
        "            while node and not node.root:\n",
        "                path.append(node)\n",
        "                node = node.parent\n",
        "            path.reverse()\n",
        "            return path\n",
        "\n",
        "        return (collect_path(node) for node in self.nodes(item))\n",
        "\n",
        "    def inspect(self):\n",
        "        # Print the tree structure\n",
        "        self.root.inspect(1)\n",
        "\n",
        "        for item, nodes in self.items():\n",
        "            for node in nodes:\n",
        "                print('    %r' % node)\n",
        "\n",
        "def conditional_tree_from_paths(paths):\n",
        "    # Construct a conditional tree from paths\n",
        "    tree = FPTree()\n",
        "    condition_item = None\n",
        "    items = set()\n",
        "\n",
        "    for path in paths:\n",
        "        if condition_item is None:\n",
        "            condition_item = path[-1].item\n",
        "\n",
        "        point = tree.root\n",
        "        for node in path:\n",
        "            next_point = point.search(node.item)\n",
        "            if not next_point:\n",
        "                # Add a new node to the tree\n",
        "                items.add(node.item)\n",
        "                count = node.count if node.item == condition_item else 0\n",
        "                next_point = FPNode(tree, node.item, count)\n",
        "                point.add(next_point)\n",
        "                tree._update_route(next_point)\n",
        "            point = next_point\n",
        "\n",
        "    assert condition_item is not None\n",
        "\n",
        "    # Calculate the counts for nodes\n",
        "    for path in tree.prefix_paths(condition_item):\n",
        "        count = path[-1].count\n",
        "        for node in reversed(path[:-1]):\n",
        "            node._count += count\n",
        "\n",
        "    return tree\n",
        "\n",
        "class FPNode(object):\n",
        "    # FP-tree node\n",
        "\n",
        "    def __init__(self, tree, item, count=1):\n",
        "        self._tree = tree\n",
        "        self._item = item\n",
        "        self._count = count\n",
        "        self._parent = None\n",
        "        self._children = {}\n",
        "        self._neighbor = None\n",
        "\n",
        "    def add(self, child):\n",
        "        # Add a child node\n",
        "\n",
        "        if not isinstance(child, FPNode):\n",
        "            raise TypeError(\"Can only add other FPNodes as children\")\n",
        "\n",
        "        if not child.item in self._children:\n",
        "            self._children[child.item] = child\n",
        "            child.parent = self\n",
        "\n",
        "    def search(self, item):\n",
        "        # Search for a child node with the given item\n",
        "        try:\n",
        "            return self._children[item]\n",
        "        except KeyError:\n",
        "            return None\n",
        "\n",
        "    def __contains__(self, item):\n",
        "        return item in self._children\n",
        "\n",
        "    @property\n",
        "    def tree(self):\n",
        "        return self._tree\n",
        "\n",
        "    @property\n",
        "    def item(self):\n",
        "        return self._item\n",
        "\n",
        "    @property\n",
        "    def count(self):\n",
        "        return self._count\n",
        "\n",
        "    def increment(self):\n",
        "        if self._count is None:\n",
        "            raise ValueError(\"Root nodes have no associated count.\")\n",
        "        self._count += 1\n",
        "\n",
        "    @property\n",
        "    def root(self):\n",
        "        return self._item is None and self._count is None\n",
        "\n",
        "    @property\n",
        "    def leaf(self):\n",
        "        return len(self._children) == 0\n",
        "\n",
        "    @property\n",
        "    def parent(self):\n",
        "        return self._parent\n",
        "\n",
        "    @parent.setter\n",
        "    def parent(self, value):\n",
        "        if value is not None and not isinstance(value, FPNode):\n",
        "            raise TypeError(\"A node must have an FPNode as a parent.\")\n",
        "        if value and value.tree is not self.tree:\n",
        "            raise ValueError(\"Cannot have a parent from another tree.\")\n",
        "        self._parent = value\n",
        "\n",
        "    @property\n",
        "    def neighbor(self):\n",
        "        return self._neighbor\n",
        "\n",
        "    @neighbor.setter\n",
        "    def neighbor(self, value):\n",
        "        if value is not None and not isinstance(value, FPNode):\n",
        "            raise TypeError(\"A node must have an FPNode as a neighbor.\")\n",
        "        if value and value.tree is not self.tree:\n",
        "            raise ValueError(\"Cannot have a neighbor from another tree.\")\n",
        "        self._neighbor = value\n",
        "\n",
        "    @property\n",
        "    def children(self):\n",
        "        return tuple(self._children.values())\n",
        "\n",
        "    def inspect(self, depth=0):\n",
        "        for child in self.children:\n",
        "            child.inspect(depth + 1)\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.root:\n",
        "            return \"<%s (root)>\" % type(self).__name__\n",
        "        return \"<%s %r (%r)>\" % (type(self).__name__, self.item, self.count)\n"
      ],
      "metadata": {
        "id": "ys5DGrOkYg1Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "dataset = new_array\n",
        "# Main function\n",
        "if __name__ == '__main__':\n",
        "    # Call find_frequent_itemsets() to generate frequent itemsets\n",
        "    start = time.time()\n",
        "\n",
        "    total_baskets = len(dataset)\n",
        "    min_support = 0.18 * total_baskets\n",
        "\n",
        "    frequent_itemsets = find_frequent_itemsets(dataset, minimum_support=min_support, include_support=True)\n",
        "\n",
        "    result = []\n",
        "    for itemset, support in frequent_itemsets:\n",
        "        result.append((itemset, support))\n",
        "\n",
        "    result = sorted(result, key=lambda i: i[0])\n",
        "    for itemset, support in result:\n",
        "        print(str(itemset) + ' ' + str(support/total_baskets))\n",
        "\n",
        "    end = time.time()\n",
        "    print('Execution time:', str(end - start))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2i7WrComqd1",
        "outputId": "44fc4df5-f11b-4a0c-cb9b-4c6369344b06"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F0'] 0.29025929025929026\n",
            "['F0', 'F5'] 0.20037220037220038\n",
            "['F0', 'F7'] 0.19007219007219006\n",
            "['F0', 'F8'] 0.19512119512119513\n",
            "['F1'] 0.2945842945842946\n",
            "['F1', 'F0'] 0.20986620986620988\n",
            "['F1', 'F2'] 0.20477520477520478\n",
            "['F1', 'F5'] 0.1950911950911951\n",
            "['F1', 'F8'] 0.1848151848151848\n",
            "['F2'] 0.2903272903272903\n",
            "['F2', 'F0'] 0.2102172102172102\n",
            "['F2', 'F0', 'F5'] 0.18019418019418018\n",
            "['F2', 'F5'] 0.2103052103052103\n",
            "['F2', 'F7'] 0.1954021954021954\n",
            "['F2', 'F8'] 0.19036019036019036\n",
            "['F3'] 0.3096883096883097\n",
            "['F3', 'F0'] 0.22032322032322033\n",
            "['F3', 'F1'] 0.19991319991319992\n",
            "['F3', 'F2'] 0.2201902201902202\n",
            "['F3', 'F4'] 0.20519620519620518\n",
            "['F3', 'F5'] 0.21042721042721044\n",
            "['F3', 'F6'] 0.2251772251772252\n",
            "['F3', 'F6', 'F0'] 0.18542018542018543\n",
            "['F3', 'F7'] 0.20004020004020004\n",
            "['F3', 'F8'] 0.18012918012918014\n",
            "['F4'] 0.30513230513230516\n",
            "['F4', 'F0'] 0.20033220033220034\n",
            "['F4', 'F1'] 0.18007418007418008\n",
            "['F4', 'F2'] 0.1808101808101808\n",
            "['F4', 'F5'] 0.18076618076618076\n",
            "['F4', 'F6'] 0.20535320535320536\n",
            "['F4', 'F7'] 0.18551818551818552\n",
            "['F4', 'F8'] 0.18026618026618027\n",
            "['F5'] 0.27540527540527543\n",
            "['F5', 'F7'] 0.18531718531718533\n",
            "['F6'] 0.3050923050923051\n",
            "['F6', 'F0'] 0.2203032203032203\n",
            "['F6', 'F1'] 0.2049012049012049\n",
            "['F6', 'F2'] 0.19028419028419027\n",
            "['F6', 'F5'] 0.20055920055920057\n",
            "['F6', 'F7'] 0.21015621015621017\n",
            "['F6', 'F8'] 0.19493719493719494\n",
            "['F7'] 0.2753212753212753\n",
            "['F7', 'F8'] 0.19000519000519\n",
            "['F8'] 0.265025265025265\n",
            "['F9'] 0.22565022565022566\n",
            "Execution time: 4.865192413330078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anytree"
      ],
      "metadata": {
        "id": "YHDMJEY53arU",
        "outputId": "af0e90f5-2958-4325-9865-7cbb9ad4f0c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting anytree\n",
            "  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anytree) (1.16.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from anytree import Node, RenderTree\n",
        "\n",
        "# Define the itemsets and their support values\n",
        "itemsets = result\n",
        "\n",
        "# Create the root node\n",
        "root = Node(\"Root\")\n",
        "\n",
        "# Create the tree nodes and add them to the tree\n",
        "for itemset, support in itemsets:\n",
        "    current_node = root\n",
        "    for item in itemset:\n",
        "        child_node = None\n",
        "        for child in current_node.children:\n",
        "            if child.name == item:\n",
        "                child_node = child\n",
        "                break\n",
        "        if child_node is None:\n",
        "            child_node = Node(item, parent=current_node)\n",
        "        current_node = child_node\n",
        "\n",
        "# Print the tree\n",
        "for pre, fill, node in RenderTree(root):\n",
        "    print(\"%s%s\" % (pre, node.name))\n"
      ],
      "metadata": {
        "id": "pdz8URQ26L1p",
        "outputId": "ecb55a4c-482c-43b2-8035-4ed32dceddc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root\n",
            "├── F0\n",
            "│   ├── F5\n",
            "│   ├── F7\n",
            "│   └── F8\n",
            "├── F1\n",
            "│   ├── F0\n",
            "│   ├── F2\n",
            "│   ├── F5\n",
            "│   └── F8\n",
            "├── F2\n",
            "│   ├── F0\n",
            "│   │   └── F5\n",
            "│   ├── F5\n",
            "│   ├── F7\n",
            "│   └── F8\n",
            "├── F3\n",
            "│   ├── F0\n",
            "│   ├── F1\n",
            "│   ├── F2\n",
            "│   ├── F4\n",
            "│   ├── F5\n",
            "│   ├── F6\n",
            "│   │   └── F0\n",
            "│   ├── F7\n",
            "│   └── F8\n",
            "├── F4\n",
            "│   ├── F0\n",
            "│   ├── F1\n",
            "│   ├── F2\n",
            "│   ├── F5\n",
            "│   ├── F6\n",
            "│   ├── F7\n",
            "│   └── F8\n",
            "├── F5\n",
            "│   └── F7\n",
            "├── F6\n",
            "│   ├── F0\n",
            "│   ├── F1\n",
            "│   ├── F2\n",
            "│   ├── F5\n",
            "│   ├── F7\n",
            "│   └── F8\n",
            "├── F7\n",
            "│   └── F8\n",
            "├── F8\n",
            "└── F9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# eclat\n",
        "https://github.com/jagdeep227/Frequent_itemset_mining/blob/main/Eclat_g.py\n"
      ],
      "metadata": {
        "id": "SVtIZ2wo0kco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eclat\n",
        "#eclat\n",
        "import time\n",
        "\n",
        "FreqItems = dict()\n",
        "support = dict()\n",
        "\n",
        "\n",
        "def eclat(prefix, items, dict_id ,minsup,cnt):\n",
        "    \n",
        "    while items:\n",
        "        i ,itids = items.pop()\n",
        "        isupp = len(itids)\n",
        "        if isupp >= minsup*cnt:\n",
        "            print(prefix + [i], isupp/len(dataset))\n",
        "            FreqItems[frozenset(prefix + [i])] = isupp\n",
        "            suffix = []\n",
        "            for j, ojtids in items:\n",
        "                jtids = itids & ojtids\n",
        "                if len(jtids ) >= minsup*cnt:\n",
        "                    suffix.append((j, jtids))\n",
        "            dict_id += 1\n",
        "            eclat(prefix +[i], sorted(suffix, key=lambda item: len(item[1]), reverse=True), dict_id ,minsup,cnt)"
      ],
      "metadata": {
        "id": "dRaVlQOSkHLe"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "items = {}\n",
        "\n",
        "for transaction_id, transaction in enumerate(dataset):\n",
        "    for item in transaction:\n",
        "        if item in items:\n",
        "            items[item].add(transaction_id)\n",
        "        else:\n",
        "            items[item] = {transaction_id}\n",
        "\n",
        "    # Convert the dictionary items into a list of tuples\n",
        "items = [(item, itids) for item, itids in items.items()]"
      ],
      "metadata": {
        "id": "vAiJEwuKlV0c"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "dataset = new_array\n",
        "# Main function\n",
        "if __name__ == '__main__':\n",
        "    # Call find_frequent_itemsets() to generate frequent itemsets\n",
        "    start = time.time()\n",
        "\n",
        "    items = {}\n",
        "\n",
        "    for transaction_id, transaction in enumerate(dataset):\n",
        "        for item in transaction:\n",
        "            if item in items:\n",
        "                items[item].add(transaction_id)\n",
        "            else:\n",
        "                items[item] = {transaction_id}\n",
        "\n",
        "    # Convert the dictionary items into a list of tuples\n",
        "    items = [(item, itids) for item, itids in items.items()]\n",
        "\n",
        "    cnt = len(dataset)\n",
        "    minsup = 0.2\n",
        "    # Function call to start ECLAT algorithm\n",
        "    eclat([], sorted(items, key=lambda item: len(item[1]), reverse=True), 1, minsup, cnt)\n",
        "\n",
        "    '''result = []\n",
        "    for itemset, support in frequent_itemsets:\n",
        "        result.append((itemset, support))'''\n",
        "\n",
        "    '''result'''\n",
        "\n",
        "    end = time.time()\n",
        "    print('Execution time:', str(end - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIUzP6VykmrA",
        "outputId": "98a745ee-e28a-4f26-a034-d86c8170be6b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F51'] 0.205001205001205\n",
            "['F43'] 0.21934621934621934\n",
            "['F20'] 0.22014322014322013\n",
            "['F56'] 0.2203832203832204\n",
            "['F22'] 0.22529122529122528\n",
            "['F23'] 0.22950722950722952\n",
            "['F1'] 0.23023523023523024\n",
            "['F18'] 0.23446323446323447\n",
            "['F12'] 0.23495723495723495\n",
            "['F10'] 0.2352062352062352\n",
            "['F16'] 0.23524223524223525\n",
            "['F37'] 0.23551323551323552\n",
            "['F13'] 0.23972623972623971\n",
            "['F8'] 0.23998623998624\n",
            "['F8', 'F26'] 0.20504120504120504\n",
            "['F44'] 0.24001524001524002\n",
            "['F44', 'F26'] 0.20012620012620014\n",
            "['F48'] 0.2401832401832402\n",
            "['F19'] 0.24454224454224455\n",
            "['F57'] 0.2449112449112449\n",
            "['F53'] 0.24493724493724495\n",
            "['F4'] 0.245005245005245\n",
            "['F28'] 0.24969724969724968\n",
            "['F42'] 0.25004425004425007\n",
            "['F45'] 0.25005025005025006\n",
            "['F9'] 0.2501992501992502\n",
            "['F14'] 0.25445125445125444\n",
            "['F14', 'F15'] 0.20443820443820443\n",
            "['F32'] 0.2545392545392545\n",
            "['F32', 'F30'] 0.2047852047852048\n",
            "['F3'] 0.2545812545812546\n",
            "['F59'] 0.25475525475525473\n",
            "['F24'] 0.2548062548062548\n",
            "['F24', 'F26'] 0.2152092152092152\n",
            "['F52'] 0.25513325513325513\n",
            "['F27'] 0.2552142552142552\n",
            "['F0'] 0.2553262553262553\n",
            "['F49'] 0.25955325955325953\n",
            "['F7'] 0.25975125975125973\n",
            "['F34'] 0.25983325983325983\n",
            "['F17'] 0.25986325986325987\n",
            "['F17', 'F46'] 0.2047062047062047\n",
            "['F17', 'F41'] 0.2052162052162052\n",
            "['F17', 'F26'] 0.21496421496421497\n",
            "['F55'] 0.26008526008526006\n",
            "['F55', 'F15'] 0.204991204991205\n",
            "['F39'] 0.26017626017626017\n",
            "['F2'] 0.26041926041926045\n",
            "['F2', 'F30'] 0.20001820001820003\n",
            "['F11'] 0.26047026047026045\n",
            "['F11', 'F58'] 0.20068420068420068\n",
            "['F11', 'F26'] 0.21551121551121552\n",
            "['F29'] 0.2647642647642648\n",
            "['F31'] 0.2648362648362648\n",
            "['F54'] 0.26517326517326517\n",
            "['F54', 'F26'] 0.21035621035621035\n",
            "['F35'] 0.2652022652022652\n",
            "['F35', 'F26'] 0.20007320007320006\n",
            "['F25'] 0.26525026525026524\n",
            "['F50'] 0.26985226985226984\n",
            "['F40'] 0.26995326995326996\n",
            "['F58'] 0.27033627033627033\n",
            "['F58', 'F38'] 0.20553220553220553\n",
            "['F58', 'F26'] 0.21035121035121035\n",
            "['F5'] 0.2704002704002704\n",
            "['F5', 'F21'] 0.2050942050942051\n",
            "['F6'] 0.2705102705102705\n",
            "['F6', 'F26'] 0.20562720562720563\n",
            "['F46'] 0.27494027494027495\n",
            "['F46', 'F38'] 0.20002520002520002\n",
            "['F21'] 0.27505427505427504\n",
            "['F21', 'F30'] 0.2003022003022003\n",
            "['F33'] 0.2795122795122795\n",
            "['F33', 'F26'] 0.20971620971620972\n",
            "['F15'] 0.27965427965427964\n",
            "['F15', 'F30'] 0.20467220467220468\n",
            "['F15', 'F26'] 0.20484720484720484\n",
            "['F30'] 0.2849142849142849\n",
            "['F30', 'F26'] 0.20506320506320505\n",
            "['F41'] 0.2859192859192859\n",
            "['F41', 'F26'] 0.205991205991206\n",
            "['F38'] 0.29545429545429547\n",
            "['F38', 'F26'] 0.21538521538521538\n",
            "['F26'] 0.29553329553329555\n",
            "Execution time: 44.46168899536133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7OQxUi4wDkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zxXLKuwwDnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def apriori(data_set, min_support):\n",
        "    '''\n",
        "    Generate frequent itemsets and their corresponding support values\n",
        "    :param data_set: Input dataset as a list of transactions [f_set]\n",
        "    :param min_support: Minimum support threshold\n",
        "    :return: Support dictionary sup_dict, {f_set: support}\n",
        "    '''\n",
        "    # Data initialization\n",
        "    min_support_count = len(data_set) * min_support\n",
        "\n",
        "    # Itemset initialization, generate frequent one-itemsets\n",
        "    c1_set = []\n",
        "    for transaction in data_set:\n",
        "        for item in transaction:\n",
        "            if [item] not in c1_set:\n",
        "                c1_set.append([item])\n",
        "    c1_set.sort()  # Sort in lexicographic order\n",
        "    c1_set = list(map(frozenset, c1_set))\n",
        "    sup_dict = gen_fk(data_set, c1_set, min_support_count)\n",
        "\n",
        "    # Iteration initialization\n",
        "    fk_dict = sup_dict\n",
        "    k = 1  # Number of items in frequent itemsets\n",
        "\n",
        "    while len(list(fk_dict.keys())) > 1:\n",
        "        ckp_set = gen_ckp(fk_dict, k)\n",
        "        ckp_set = cut(ckp_set, fk_dict, k)\n",
        "        fk_dict = gen_fk(data_set, ckp_set, min_support_count)\n",
        "        sup_dict.update(fk_dict)\n",
        "        k += 1\n",
        "\n",
        "    # Calculate support values as support count divided by the length of the dataset\n",
        "    sup_dict = {itemset: support / len(data_set) for itemset, support in sup_dict.items()}\n",
        "\n",
        "    return sup_dict\n",
        "\n",
        "\n",
        "def gen_fk(data_set, ck_set, min_support_count):\n",
        "    '''\n",
        "    Scan the database and prune the set of candidate k-itemsets to generate the set of frequent k-itemsets.\n",
        "    :param data_set: The Mashroom dataset, data structure: [f_set]\n",
        "    :param ck_set: The set of candidate k-itemsets, data structure: [f_set]\n",
        "    :param min_support: Support threshold\n",
        "    :return: The support dictionary fk_dict, data structure: {f_set: support}\n",
        "    '''\n",
        "    fk_dict = {}\n",
        "    for candidate in ck_set:  # candidate is a candidate itemset, data structure: set (to use the issubset function)\n",
        "        support_count = 0  # Initial support count for each candidate itemset is set to 0\n",
        "        for transaction in data_set:  # Convert list elements to frozenset\n",
        "            if candidate.issubset(transaction):\n",
        "                support_count += 1\n",
        "        if support_count >= min_support_count:\n",
        "            fk_dict[candidate] = support_count\n",
        "    return fk_dict\n",
        "\n",
        "def gen_ckp(fk_dict, k):\n",
        "    '''\n",
        "    Generate the set of candidate (k+1)-itemsets.\n",
        "    :param fk_dict: The set of frequent k-itemsets, data structure: {f_set: support}\n",
        "    :param k: Size of frequent itemsets k\n",
        "    :return: The set of candidate (k+1)-itemsets, data structure: [f_set]\n",
        "    '''\n",
        "    fk_set = list(fk_dict.keys())\n",
        "    ckp_set = []\n",
        "    n_f = len(fk_set)\n",
        "    for i in range(n_f - 1):\n",
        "        for j in range(i + 1, n_f):\n",
        "            temp1 = list(fk_set[i])[:(k - 1)]\n",
        "            temp2 = list(fk_set[j])[:(k - 1)]\n",
        "            temp1.sort()\n",
        "            temp2.sort()\n",
        "            if temp1 == temp2:\n",
        "                ckp_set.append(fk_set[i] | fk_set[j])\n",
        "    return ckp_set\n",
        "\n",
        "def cut(ckp_set, fk_dict, k):\n",
        "    '''Prune using the Apriori principle'''\n",
        "    for candidate in ckp_set:\n",
        "        sub_set_list = list(combinations(candidate, k))\n",
        "        for sub_set in sub_set_list:\n",
        "            if frozenset(sub_set) not in fk_dict:\n",
        "                ckp_set.remove(candidate)\n",
        "                break\n",
        "    return ckp_set\n"
      ],
      "metadata": {
        "id": "c0wNGvLtwDqS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = new_array\n",
        "min_support = 0.2\n"
      ],
      "metadata": {
        "id": "iTXUUf2Pxmlf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVwMyq3c0AZs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}